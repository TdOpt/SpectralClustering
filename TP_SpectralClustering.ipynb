{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Spectral Clustering and Semi-Supervised Learning\n",
    "\n",
    "#### This notebook contains different values and imports that can be used in this practical session.\n",
    "#### Please keep the same variable names when provided in your report to make the work of teaching assistants easier. \n",
    "#### You can still change the values given or the sizes of the datasets treated if you believe it is usefull to illustrate your point.\n",
    "\n",
    "#### You can directly edit the markdown boxes to add your comments and answers to the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 1 (imports and advised values):\n",
    "from sklearn.datasets import make_moons\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.style.use('seaborn-notebook')\n",
    "\n",
    "n_samples = 200 # You can change these values\n",
    "noise_level_list = [.05, .1, .2] # You can change these values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A dictionnary which maps the noise level to the correponding moon dataset (if it has already been generated)\n",
    "noisy_moons = {} \n",
    "for lev in noise_level_list:\n",
    "    noisy_moons[lev] = make_moons(n_samples, shuffle = False, noise=lev)\n",
    "    \n",
    "f, a = plt.subplots(1, len(noise_level_list))\n",
    "f.subplots_adjust(wspace = 0.5, hspace=0.5)\n",
    "\n",
    "for i, lev in enumerate(noisy_moons):\n",
    "    a[i].scatter(noisy_moons[lev][0][:,0], noisy_moons[lev][0][:,1], c = noisy_moons[lev][1])\n",
    "    a[i].set_title('Noise = %.2f' % lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 2 :\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "n_neighbors_list = [1, 5, 10] # You can change these values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_kneighbors_graph(axes, graph, pts, noise, k):\n",
    "    axes.scatter(pts[:, 0], pts[:, 1], marker='.')\n",
    "    xidx, yidx = graph.nonzero()\n",
    "    for i, j in zip(xidx, yidx):\n",
    "        if i < j:\n",
    "            axes.plot([pts[i, 0], pts[j, 0]], [pts[i, 1], pts[j, 1]], linewidth=0.5, c='g')\n",
    "    axes.set_title('Noise =  %.2f, k = %.1f' % (noise, k),fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate the adjacency matrices\n",
    "kNN_graphs = {}\n",
    "for k in n_neighbors_list:\n",
    "    for lev in noise_level_list:\n",
    "        kNN_graphs[k, lev] = kneighbors_graph(noisy_moons[lev][0], k, mode='distance', p=2)\n",
    "\n",
    "f, a = plt.subplots(len(n_neighbors_list), len(noise_level_list))\n",
    "f.subplots_adjust(wspace = 0.5, hspace=0.5)\n",
    "for i, k in enumerate(n_neighbors_list):\n",
    "    for j, lev in enumerate(noise_level_list):\n",
    "        plot_kneighbors_graph(a[i, j], kNN_graphs[k, lev], noisy_moons[lev][0], lev, k)\n",
    "        #a[i, j].imshow(kNN_graphs[k, lev].todense(), cmap = 'Greys', interpolation=\"none\")\n",
    "        #a[i, j].set_title('Noise =  %.2f, k = %.1f' % (lev, k),fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 3 : Optimization problem \n",
    "\n",
    "- Given a graph $\\mathcal{G} = (E,V)$, let $D$ be its degree matrix and $W$ its weighted ajacency matrix, such that $L := D - W$ is the Laplacian of the graph. In the case when we consider a partition in 2 subsets $A,\\bar{A}$, the Normalized Cut problem translates as the following optimization problem:\n",
    "\n",
    "\n",
    "\n",
    "- $\\min_A \\{ f^\\top L f \\} \\text{ s.t. } f_i = \n",
    "\\begin{cases}\n",
    "    \\sqrt{\\frac{\\text{Vol}(\\bar{A})}{\\text{Vol}(A)}},& \\text{if } v_i\\in A\\\\\n",
    "    \\sqrt{\\frac{\\text{Vol}(A)}{\\text{Vol}(\\bar{A})}},& \\text{if } v_i\\in \\bar{A}\n",
    "\\end{cases}, Df \\bot \\mathbb{1}, f^\\top D f = \\text{Vol}(V)$\n",
    "\n",
    "\n",
    "- This problem is then relaxed as $\\min_{f\\in \\mathbb{R}^n} f^\\top L f \\text{ s.t. } Df \\bot \\mathbb{1}, f^\\top D f = \\text{Vol}(V)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4 : Complete the code in the box below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "f, a = plt.subplots(len(n_neighbors_list), len(noise_level_list))\n",
    "f.subplots_adjust(wspace = 0.5, hspace=0.5)\n",
    "labels = {}\n",
    "for i, k in enumerate(n_neighbors_list):\n",
    "    for j, l in enumerate(noise_level_list):\n",
    "        spectral = SpectralClustering(n_clusters=2, eigen_solver='arpack', affinity=\"precomputed\")\n",
    "        labels[k, l] = spectral.fit_predict(kneighbors_graph(noisy_moons[l][0], k, mode='distance', p=2).todense())\n",
    "        a[i, j].scatter(noisy_moons[l][0][:,0], noisy_moons[l][0][:,1], c = labels[k, l])\n",
    "        a[i, j].set_title('Noise =  %.2f, k = %.1f' % (l, k), fontsize = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that increasing the number improves the robustness of the clustering.\n",
    "However, since it makes the adjacency matrix denser, it also makes the complexity greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The Frobenius inner product for matrices\n",
    "def frobenius(A, B):\n",
    "    return np.sum(np.multiply(A,B))\n",
    "\n",
    "#Compute the matrix representation C of a given clustering\n",
    "#ie Cij = 1 iff xi and xj are clustered together and i != j\n",
    "def matrix_clustering(labels):\n",
    "    n = len(labels)\n",
    "    C = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (labels[i] == labels[j] and i != j):\n",
    "                C[i,j] = 1\n",
    "    return C\n",
    "\n",
    "def cosine_similarity(C1, C2):\n",
    "    return frobenius(C1, C2) / (np.linalg.norm(C1, 'fro')*np.linalg.norm(C2, 'fro'))\n",
    "\n",
    "#Return the average cosine similarity between a reference clustering and bootstrapped clusterings over B runs\n",
    "def cluster_stability(X, algo, clusters=2, B=10, f=0.8):\n",
    "    n = X.shape[0]\n",
    "    ref = algo(X, clusters)\n",
    "    \n",
    "    avg_similarity = 0\n",
    "    \n",
    "    for i in range(B):\n",
    "        indices = np.random.choice(n, f * n, replace=False)\n",
    "        bootstrapped = X[indices, :]\n",
    "        c = algo(bootstrapped, clusters)\n",
    "        avg_similarity += cosine_similarity(matrix_clustering(c), matrix_clustering(ref[indices]))\n",
    "        \n",
    "    return avg_similarity / B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the stability as a function of the number of neighbors used for spectral clustering, on noisy and non-noisy versions of the moon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_free_stability = []\n",
    "noisy_stability = []\n",
    "n_neighbors_list = np.arange(1,11,2)\n",
    "for k in n_neighbors_list:\n",
    "    noisy_stability.append(\n",
    "        cluster_stability(noisy_moons[.2][0], \n",
    "            (lambda X, clusters: SpectralClustering(n_clusters=clusters, \n",
    "                            affinity=\"precomputed\").fit_predict(kneighbors_graph(X, k, mode='distance', p=2).todense())),\n",
    "            B=50, f=0.8))\n",
    "    noise_free_stability.append(\n",
    "        cluster_stability(noisy_moons[.05][0], \n",
    "            (lambda X, clusters: SpectralClustering(n_clusters=clusters, \n",
    "                            affinity=\"precomputed\").fit_predict(kneighbors_graph(X, k, mode='distance', p=2).todense())), \n",
    "            B=50, f=0.8))\n",
    "\n",
    "plt.plot(n_neighbors_list, noisy_stability, label = \"Noisy\")\n",
    "plt.plot(n_neighbors_list, noise_free_stability, label = \"Noise-free\")\n",
    "plt.title(\"Stability of Spectral Clustering as a function of the number of neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "noise_free_stability = []\n",
    "noisy_stability = []\n",
    "n_neighbors_list = np.arange(1,11,2)\n",
    "\n",
    "for k in n_neighbors_list:\n",
    "    noisy_stability.append(\n",
    "        cluster_stability(noisy_moons[.2][0], \n",
    "            (lambda X, clusters: AgglomerativeClustering(n_clusters=2, affinity='euclidean', \n",
    "            connectivity=kneighbors_graph(X, k, mode='distance', p=2).todense(), linkage='ward').fit_predict(X)),B=20, f=0.8))\n",
    "    noise_free_stability.append(\n",
    "        cluster_stability(noisy_moons[.05][0], \n",
    "            (lambda X, clusters: AgglomerativeClustering(n_clusters=2, affinity='euclidean', \n",
    "            connectivity=kneighbors_graph(X, k, mode='distance', p=2).todense(), linkage='ward').fit_predict(X)),B=20, f=0.8))\n",
    "\n",
    "plt.plot(n_neighbors_list, noisy_stability, label = \"Noisy\")\n",
    "plt.plot(n_neighbors_list, noise_free_stability, label = \"Noise-free\")\n",
    "plt.title(\"Stability of Agglomerative Clustering as a function of the number of neighbors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on MNIST\n",
    "\n",
    "TODO : develop this part (make the number of clusters vary, visualize the clusters (PCA ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()\n",
    "\n",
    "mnist_stability = []\n",
    "n_neighbors_list = np.arange(1,11,2)\n",
    "for k in n_neighbors_list:\n",
    "    mnist_stability.append(\n",
    "        cluster_stability(mnist.data, \n",
    "            (lambda X, clusters: SpectralClustering(n_clusters=clusters, \n",
    "                            affinity=\"precomputed\").fit_predict(kneighbors_graph(X, k, mode='distance', p=10).todense())),\n",
    "            B=20, f=0.8))\n",
    "\n",
    "plt.plot(n_neighbors_list, mnist_stability)\n",
    "plt.title(\"Stability of Spectral Clustering as a function of the number of neighbors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning\n",
    "\n",
    "Choice of the dataset used : **Precise** which dataset you chose and why it is relevant for the semi-supervised learning Task\n",
    "\n",
    "Advised datasets :\n",
    "\n",
    "*Breast Cancer Wisconsin (Diagnostic) Database*\n",
    "\n",
    "*MNIST binary even vs odd (multiple clusters inside each class)*\n",
    "\n",
    "Feel free to use other datasets if they are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "### For all the next questions, use Cancer and Mnist classes to handle your data if you choose to use these one,\n",
    "### You can also add more datasets but we advise you to handle them with this class for better readability\n",
    "class semi_sup_dat:\n",
    "    def __init__(self,data,p_unlabelled,name):\n",
    "        # DON T CHANGE THE RANDOM STATES\n",
    "        self.name = name\n",
    "        if self.name == 'Mnist':\n",
    "            # do an even vs odd binary classification :\n",
    "            even = [0,2,4,6,8]\n",
    "            Y = np.array([int(y in even) for y in data.target])\n",
    "        else:\n",
    "            Y = data.target\n",
    "        X_lab, X_unlab, y_lab, y_unlab = train_test_split(data.data, Y, test_size=p_unlabelled, random_state=32)\n",
    "        self.X_lab = X_lab\n",
    "        self.X_unlab = X_unlab\n",
    "        self.y_lab = y_lab\n",
    "        self.y_unlab = y_unlab\n",
    "\n",
    "\n",
    "# The following lines can be called later in the code to build a dataset with varying unlabelled proportion\n",
    "p_unlabelled = 0.8 # You can change this value\n",
    "cancer = load_breast_cancer()\n",
    "Cancer = semi_sup_dat(cancer, p_unlabelled,'Cancer')\n",
    "\n",
    "digits = load_digits()\n",
    "Mnist = semi_sup_dat(digits, p_unlabelled,'Mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Question 9  : Complete the function self_training\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def self_training_kNN(X, neighbors = 3):\n",
    "    X_lab = X.X_lab.copy()\n",
    "    y_lab = X.y_lab.copy()    \n",
    "    X_unlab = X.X_unlab.copy()\n",
    "    y_unlab = X.y_unlab.copy() \n",
    "    \n",
    "    for i in range(len(y_unlab)):\n",
    "        kNN = KNeighborsClassifier(neighbors, n_jobs = -1)\n",
    "        kNN.fit(X_lab,y_lab)\n",
    "    \n",
    "        y_tmp = kNN.predict_proba(X_unlab)\n",
    "        \n",
    "        #Get the most probable prediction\n",
    "        #couple of indices: (index of sample, class)\n",
    "        idx,c = np.unravel_index(np.argmax(y_tmp), y_tmp.shape)\n",
    "\n",
    "        \n",
    "        X_lab = np.vstack([X_lab,X_unlab[idx,:]])\n",
    "        y_lab = np.hstack([y_lab, [c]])\n",
    "        \n",
    "        y_unlab[idx] = c\n",
    "        X_unlab = np.delete(X_unlab,idx,0)\n",
    "        \n",
    "        \n",
    "    return y_unlab\n",
    "\n",
    "\n",
    "#When the 2 classes are 0,1, this is the error\n",
    "def l1_loss (y_pred, data):\n",
    "    return (np.linalg.norm(y_pred - data.y_unlab,1)/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test self-training on the cancer and mnist datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = self_training_kNN(Cancer, 3)\n",
    "print 100 * l1_loss(y_pred, Cancer)\n",
    "\n",
    "y_pred_mnist = self_training_kNN(Mnist, 3)\n",
    "print 100 * l1_loss(y_pred_mnist, Mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel # Or reimplement it yourself if your prefer\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 : Complete the code in the box below\n",
    "\n",
    "We aim at solving \n",
    "$$\\min_{f\\in \\mathcal{H}_\\mathcal{K}} \\frac{1}{l}\\sum_{i = 1}^l (y_i - f(x_i))^2 + \\lambda\\Vert f \\Vert_{\\mathcal{H}_\\mathcal{K}}^2 + \\frac{\\lambda_u}{u+l} f^\\top L f$$\n",
    "\n",
    "\n",
    "By applying the representer theorem, we get that there exits a vector $\\alpha \\in \\mathbb{R}^{l+u}$ such that the solution is of the form $f(.) = \\sum_{i=1}^{l+u} \\mathcal{K}(.,x_i)\\alpha_i$\n",
    "\n",
    "Let us denote $K$ the kernel matrix $\\lbrace\\mathcal{K}(x_i,x_j)\\rbrace_{i,j}$. Pluggin this expresssion into our minimization problem, we have that\n",
    "\n",
    "$\\begin{align}\n",
    "\\frac{1}{l}\\sum_{i = 1}^l (y_i - f(x_i))^2 &= \\frac{1}{l}\\sum_{i = 1}^l (y_i - \\sum_{j=1}^{l+u}\\mathcal{K}(x_i,x_j)\\alpha_j)^2\\\\\n",
    "&= \\frac{1}{l}\\Vert y \\Vert_2^2 - \\frac{2}{l}\\sum_{i=1}^{l}\\sum_{j=1}^{l+u}y_i\\alpha_j\\mathcal{K}(x_i,x_j) + \\frac{1}{l} \\sum_{j=1}^{l+u}\\sum_{l=1}^{l+u}\\alpha_j\\alpha_i\\mathcal{K}(x_i,x_j)\\\\\n",
    "&= \\frac{1}{l}\\Vert y \\Vert_2^2 - \\frac{2}{l} y^\\top K \\alpha + \\frac{1}{l}\\alpha^\\top K \\alpha\n",
    "\\end{align}$\n",
    "\n",
    "where $y \\in \\mathbb{R}^{l+u}, \\forall  j \\geq l, y_i = 0$ is the zero-padded vector of known labels.\n",
    "\n",
    "\n",
    "We also have that \n",
    "\n",
    "$\\begin{align}\n",
    "\\Vert f \\Vert_{\\mathcal{H}_\\mathcal{K}}^2 &=  <\\sum_{i=1}^{l+u} \\mathcal{K}(.,x_i)\\alpha_i, \\sum_{i=1}^{l+u} \\mathcal{K}(.,x_j)\\alpha_j >_{\\mathcal{H}_\\mathcal{K}}\\\\\n",
    "&= \\sum_{i,j} \\alpha_i \\alpha_j \\mathcal{K}(x_i, x_j) \\text{ by the reproducing property of }\\mathcal{K(.,.)} \\\\\n",
    "&= \\alpha^\\top K \\alpha\n",
    "\\end{align}$\n",
    "\n",
    "and \n",
    "\n",
    "$\\begin{align}\n",
    "\\boldsymbol{f}^\\top L \\boldsymbol{f} &= \\sum_{ij} f(x_i) l_{ij} f_(x_j)\\\\\n",
    "&= \\sum_{ij}\\sum_{p,q}  \\alpha_p K_{ip}l_{ij} K_{jq} \\alpha_q\\\\\n",
    "&= \\alpha^\\top K^\\top L K\\alpha\n",
    "\\end{align}$\n",
    "\n",
    "Getting rid of the terms that do not play a role in the minimization, and taking the symmetry of $K$ into account, we can therefore rewrite our minimization problem as\n",
    "\n",
    "$$\\min_{\\alpha \\in \\mathbb{R}^{l+u}}  \\frac{1}{l}\\alpha^\\top K \\alpha  - \\frac{2}{l} y^\\top K \\alpha +  \\lambda\\alpha^\\top K \\alpha + \\frac{\\lambda_u}{u+l} \\alpha^\\top K L K\\alpha$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\\min_{\\alpha \\in \\mathbb{R}^{l+u}}  \\alpha^\\top [(\\frac{1}{l} + \\lambda) K + \\frac{\\lambda_u}{u+l} K L K] \\alpha  - \\frac{2}{l} y^\\top K \\alpha$$\n",
    "\n",
    "\n",
    "Since this is a convex minimization problem, at the optimum the gradient of the objective function vanishes, i.e. its solution $\\alpha^\\star$ verifies\n",
    "\n",
    "$$[(\\frac{1}{l} + \\lambda) K + \\frac{\\lambda_u}{u+l} K L K]\\alpha^\\star = \\frac{2}{l} K y$$\n",
    "\n",
    "which finally yields \n",
    "\n",
    "$$ \\alpha^\\star = \\frac{2}{l} [(\\frac{1}{l} + \\lambda) K + \\frac{\\lambda_u}{u+l} K L K]^{-1}K y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 : Add your answer here\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14 : Complete the code in the box below\n",
    "\n",
    "##### Add your answer to the question here :\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15 : Complete the code in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16 : Complete the code in the box below\n",
    "\n",
    "###### Describe your protocol here : \n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
